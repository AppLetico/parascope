# Prscope Environment Variables
# Copy this file to .env and fill in your values

# =============================================================================
# GitHub (required for syncing PRs)
# =============================================================================

# GitHub Personal Access Token
# Create at: https://github.com/settings/tokens
# Required scopes: repo (for private repos) or public_repo (for public only)
GITHUB_TOKEN=ghp_your_token_here

# =============================================================================
# LLM Providers (optional - only needed if llm.enabled: true)
# =============================================================================

# OpenAI (for gpt-4o, gpt-4-turbo, gpt-3.5-turbo, o1, etc.)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key

# Anthropic (for claude-3-opus, claude-3-sonnet, claude-3-haiku, etc.)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Google AI (for gemini-pro, gemini-1.5-pro, etc.)
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key

# Azure OpenAI (for azure/gpt-4, azure/gpt-35-turbo, etc.)
# AZURE_API_KEY=your-azure-key
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-15-preview

# AWS Bedrock (for bedrock/anthropic.claude-v2, bedrock/amazon.titan-text, etc.)
# Uses AWS credentials from environment or ~/.aws/credentials
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# AWS_REGION_NAME=us-east-1

# Ollama (local models - no API key needed)
# Just ensure Ollama is running: ollama serve
# Use models like: ollama/llama2, ollama/mistral, ollama/codellama

# =============================================================================
# See https://docs.litellm.ai/docs/providers for all supported providers
# =============================================================================
